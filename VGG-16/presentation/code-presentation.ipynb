{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e036b527-e921-485d-bbcd-a38315080257",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e0f88-cc6c-4b15-af81-166773b2be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import nn,np\n",
    "\n",
    "\n",
    "class SimplifiedVGG(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.3):\n",
    "        super(SimplifiedVGG, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "    \n",
    "                nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                \n",
    "                nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                \n",
    "                nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                \n",
    "                nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                \n",
    "                nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 2048), nn.BatchNorm1d(2048), nn.ReLU(inplace=True), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.ReLU(inplace=True), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True), nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1650c-2821-4c39-942d-2ac7e055e6cb",
   "metadata": {},
   "source": [
    "# basic configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a0b6a-eab1-4ee0-958d-83e8abd624ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "K_FOLDS = 3\n",
    "PATIENCE = 7\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a625e2-6019-4a38-8ada-d89f22cd7dbb",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebeb191-c3d6-4b23-8b02-efca3383e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from train import Trainer\n",
    "\n",
    "\n",
    "def run_hyperparameter_tuning():\n",
    "   \n",
    "    os.makedirs(PARAMS_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "    param_space = {\n",
    "        \"Adam\": [\n",
    "            {\"learning_rate\": 0.001, \"batch_size\": 64},\n",
    "            {\"learning_rate\": 0.0005, \"batch_size\": 64},\n",
    "            {\"learning_rate\": 0.0005, \"batch_size\": 128}\n",
    "        ],\n",
    "        \"SGD\": [\n",
    "            {\"learning_rate\": 0.01, \"batch_size\": 32},\n",
    "            {\"learning_rate\": 0.005, \"batch_size\": 64},\n",
    "            {\"learning_rate\": 0.001, \"batch_size\": 128}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for opt_type, configs in param_space.items():\n",
    "        best_acc = 0\n",
    "        best_config = None\n",
    "\n",
    "        for config in configs:\n",
    "            print(f\"\\nTrying Hyperparameters: {config} with Optimizer: {opt_type}\")\n",
    "            trainer = Trainer(\n",
    "                learning_rate=config[\"learning_rate\"],\n",
    "                batch_size=config[\"batch_size\"],\n",
    "                optimizer_type=opt_type\n",
    "            )\n",
    "            val_acc = trainer.train(return_best_val_acc=True)\n",
    "\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_config = config\n",
    "\n",
    "     \n",
    "        result = {\"best_acc\": best_acc, \"best_config\": best_config}\n",
    "        np.save(os.path.join(PARAMS_PATH, f\"best_params_{opt_type}.npy\"), result)\n",
    "\n",
    "        print(f\"\\n Best Hyperparameters for {opt_type}: {best_config} with Accuracy: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3093e4-db6c-44f7-bc25-0bdca4add73d",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9c64b-5f69-4a91-9e55-df73077312bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d69437-5093-452c-bd02-9d32514de906",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\widetilde{y}_i &= \\lambda\\,\\mathbf{1}_{y_i} + (1 - \\lambda)\\,\\mathbf{1}_{y_j}, \\\\[6pt]\n",
    "\\widetilde{y}_i &:\\ \\text{mixed (soft) label for sample }i,\\\\\n",
    "\\mathbf{1}_{y_i} &:\\ \\text{one-hot vector of length }C\\text{ with a 1 at index }y_i,\\\\\n",
    "\\mathbf{1}_{y_j} &:\\ \\text{one-hot vector of length }C\\text{ with a 1 at index }y_j,\\\\\n",
    "y_i &:\\ \\text{ground-truth class label of sample }i,\\\\\n",
    "y_j &:\\ \\text{ground-truth class label of the sample paired to }i,\\\\\n",
    "\\lambda &:\\ \\text{mixing coefficient sampled from }\\mathrm{Beta}(\\alpha,\\alpha).\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a38e3f-6112-4e23-b03f-b46aedc2e338",
   "metadata": {},
   "source": [
    "1. Learns better patterns\n",
    "2. Handles noise better\n",
    "3. Improves generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7e2b2-49cd-4946-b38d-93f0b3e1fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import torch, np, optim, DEVICE, NUM_CLASSES, NUM_EPOCHS, K_FOLDS, PATIENCE, KFold, DataLoader, Subset, load_dataset\n",
    "from model import SimplifiedVGG\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, learning_rate=0.001, batch_size=32, optimizer_type=\"Adam\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = DEVICE\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        self.num_epochs = NUM_EPOCHS\n",
    "        self.k_folds = K_FOLDS\n",
    "        self.patience = PATIENCE\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.train_loader, _ = load_dataset.load_dataset(batch_size=self.batch_size, path=\"/scratch/username\")\n",
    "        self.kf = KFold(n_splits=self.k_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    def get_optimizer(self, model):\n",
    "        if self.optimizer_type == \"Adam\":\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
    "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        elif self.optimizer_type == \"SGD\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=self.learning_rate,\n",
    "                steps_per_epoch=len(self.train_loader),\n",
    "                epochs=self.num_epochs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer type\")\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def train(self, return_best_val_acc=False):\n",
    "        fold_results = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(range(len(self.train_loader.dataset)))):\n",
    "            print(f\"\\nFold {fold+1}/{self.k_folds}\")\n",
    "            \n",
    "            best_val_loss = np.inf\n",
    "            epochs_no_improve = 0\n",
    "            history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "            train_subset = Subset(self.train_loader.dataset, train_idx)\n",
    "            val_subset = Subset(self.train_loader.dataset, val_idx)\n",
    "            train_loader = DataLoader(train_subset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "            val_loader = DataLoader(val_subset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "            model = SimplifiedVGG().to(self.device)\n",
    "            criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.01)\n",
    "            optimizer, scheduler = self.get_optimizer(model)\n",
    "\n",
    "            for epoch in range(self.num_epochs):\n",
    "                model.train()\n",
    "                running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "                for images, labels in train_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device).long()\n",
    "                    optimizer.zero_grad()\n",
    "                    images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.2)\n",
    "                    outputs = model(images)\n",
    "                    loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    correct_train += (predicted == labels).sum().item()\n",
    "                    total_train += labels.size(0)\n",
    "\n",
    "               \n",
    "                model.eval()\n",
    "                correct_val, total_val, val_loss = 0, 0, 0.0\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in val_loader:\n",
    "                        images, labels = images.to(self.device), labels.to(self.device).long()\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        _, predicted = outputs.max(1)\n",
    "                        correct_val += (predicted == labels).sum().item()\n",
    "                        total_val += labels.size(0)\n",
    "\n",
    "                val_accuracy = 100 * correct_val / total_val\n",
    "                print(f\"Epoch [{epoch+1}/{self.num_epochs}], Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "                epoch_train_loss = running_loss / len(train_loader)\n",
    "                epoch_train_acc = 100 * correct_train / total_train\n",
    "                epoch_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "                if epoch_val_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_val_loss\n",
    "                    epochs_no_improve = 0\n",
    "                    torch.save(model.state_dict(), f\"best_model_{self.optimizer_type}.pth\")\n",
    "                    print(f\"Val Loss Improved. Model saved at epoch {epoch+1}\")\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "                if epochs_no_improve >= self.patience:\n",
    "                    print(f\"\\nEarly stopping at epoch {epoch+1} due to no improvement for {self.patience} epochs.\")\n",
    "                    break\n",
    "\n",
    "                history[\"train_loss\"].append(epoch_train_loss)\n",
    "                history[\"val_loss\"].append(epoch_val_loss)\n",
    "                history[\"train_acc\"].append(epoch_train_acc)\n",
    "                history[\"val_acc\"].append(val_accuracy)\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "            fold_results.append(val_accuracy)\n",
    "            np.save(f\"training_history_{self.optimizer_type}_fold_{fold}.npy\", history)\n",
    "            print(f\"Training history saved for fold {fold}.\")\n",
    "\n",
    "        avg_val_acc = np.mean(fold_results)\n",
    "        print(f\"\\n Average Validation Accuracy ({self.optimizer_type}): {avg_val_acc:.2f}%\")\n",
    "        print(f\"Estimated Test Error: {100 - avg_val_acc:.2f}%\")\n",
    "\n",
    "        if return_best_val_acc:\n",
    "            return max(fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889ab3e-6592-4f81-884a-608237dffd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada5b97-c894-4f4b-b185-3c2e3cf0b936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915b4bb-09b3-43f7-a375-2e78d59bbebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55b3b6-f611-41c8-9dd3-f0abf95e037b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd3507-1730-4c68-8f4c-1b7fe5040017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709abe55-a711-4e33-896d-a7d2c8c09802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cb30c09-24c3-4763-9c2d-a9191f20e5e0",
   "metadata": {},
   "source": [
    "# Predicting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8a95f-3059-4ebb-b59b-ba49bb17531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from model import SimplifiedVGG\n",
    "from config import DEVICE, NUM_CLASSES\n",
    "from augmentation import produce_image\n",
    "\n",
    "IMAGE_PATH = input(\"Enter the path of the image file: \")\n",
    "IMAGE_SIZE = 56\n",
    "MODEL_PATH = \"best_model_Adam.pth\"\n",
    "CLASS_NAMES = [f\"Class {i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    raw_img = Image.open(image_path).convert(\"RGB\")\n",
    "    rng = np.random.default_rng(seed=1)\n",
    "    processed_img, _ = produce_image(raw_img, resolution=IMAGE_SIZE, rng=rng)\n",
    "    input_tensor = tensor_transform(processed_img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    model = SimplifiedVGG(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "\n",
    "    plt.imshow(raw_img)\n",
    "    plt.title(f\"Predicted: {CLASS_NAMES[predicted_class]} ({confidence*100:.1f}%) - Adam\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    image_basename = os.path.basename(image_path).split('.')[0]\n",
    "    output_path = f\"{image_basename}_prediction.png\"\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Prediction saved as {output_path}\")\n",
    "\n",
    "predict_image(IMAGE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
